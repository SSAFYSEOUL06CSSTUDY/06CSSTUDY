# 1. 메모리 계층
> 메모리를 필요에 따라 나누어 두는 것 -> CPU가 메모리에 더 빨리 접근 가능하다
- 상황에 맞게 사용하자

<img width="506" alt="메모리 계층 구조" src="https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/50acf59c-d6f4-4a8b-8276-d5038113feb9"><br>
- 레지스터: CPU 안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적음
- 캐시(L1, L2 캐시): 휘발성, 속도 빠름, 기억 용량 적음, L3도 있다
- 메모리(주기억장치, RAM): 휘발성, 속도 보통, 기억 용량 보통
- 보조기억장치(HDD, SSD): 비휘발성, 속도 낮음, 기억 용량 많음

## 캐시
> 데이터나 값을 미리 복사해 놓는 임시 장소
- 메모리와 CPU 사이의 속도 차이가 크기 때문에 중간에 `캐싱 계층`을 둬서 해결한다
- 캐시 계층을 두지 말고 캐시를 직접 설정할 때는?
  -> 자주 사용하는 데이터를 기반으로 설정해야 한다. 이에 대한 근거는 `지역성`이다.

### 지역성
- 시간 지역성: 최근 사용한 데이터에 다시 접근하려는 특성
- 공간 지역성: 최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성

## 캐시히트와 캐시미스
![캐시히트와 캐시미스](https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/2a76499c-0947-45b5-adc1-9f25801913d2)
- `캐시히트`: 캐시에서 원하는 데이터를 찾음. 위치도 가깝고 CPU 내부 버스 기반으로 작동하기 때문에 빠름.
- `캐시미스` : 캐시에 원하는 데이터가 없어서 주메모리에 가서 찾아오는 것. 시스템 버스를 기반으로 작동하기 때문에 느림.

## 캐시매핑
> 캐시가 히트되기 위해 매핑하는 방법
- 레지스터는 굉장히 작고 주 메모리는 굉장히 크기 때문에 작은 레지스터가 캐시 계층으로써 역할을 잘 해주려면 이 매핑을 어떻게 하느냐가 중요함

|이름|설명|
|---|-----------------------------------------------------------------------------------------------------------------|
|직접 매핑<br>(Direct Mapping)|- 메모리 주소와 캐시의 순서를 일치 시켜 지정된 캐시 라인으로만 사상하는 방식<br>- 캐시 1에는 메모리 1~10번을, 캐시 2에는 메모리 11~20번을 위치시키는 것<br>- 적중률과 성능이 낮지만 구현이 간단하고 쉬운 방법|
|연관 매핑<br>(Associative Mapping)|- 순서를 일치시키지 않고 필요한 메모리 값을 캐시의 어디든 편하게 저장<br>- 찾는 과정은 복잡하고 느리지만 필요한 캐시 위주로 저장하기에 적중률은 높다|
|직접 연관 매핑<br>(Set Associative Mapping)|- 연관매핑과 직접매핑을 합쳐놓은 방식.<br>- 순서를 일치시키면서 일정 그룹을 두지만, 그 그룹내에서는 편하게 저장하는 방식<br>- 블록화가 되어있어 검색에 조금더 효율적이며 적중률이 많이 떨어지지도 않는다|

### 쿠키
> 만료기한이 있는 키-값 저장소  
- 4KB까지 데이터를 저장할 수 있고 만료 기한을 정할 수 있음
- 쿠키 설정 시 `document.cookie`로 쿠키를 볼 수 없게 httponly 옵션을 거는 것이 중요
- 클라이언트 또는 서버에서 만료기한 등을 정할 수 있고 보통 서버에서 정함

### 로컬 스토리지
> 만료기한이 없는 키-값 저장소  
- 10MB까지 저장 가능
- 웹 브라우저를 닫아도 유지되고 도메인 단위로 저장, 생성
- HTML5를 지원하지 않는 웹 브라우저에서는 사용 불가능
- 클라이언트에서만 수정 가능

### 세션 스토리지
> 만료기한이 없는 키-값 저장소  
- 5MB까지 저장 가능
- 탭 단위로 세션 스토리지를 생성, 탭을 닫을 때 해당 데이터가 삭제
- HTML5 지원 브라우저에서만 사용 가능
- 클라이언트에서만 수정 가능

## 데이터베이스의 캐싱 계층
![데이터베이스의 캐싱 계층](https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/2b8a4617-4812-4dfc-9f88-c5e9019f9634)
- 메인 데이터베이스 위에 레디스(redis) 데이터 베이스 계층을 `캐싱 계층`으로 둬서 성능을 향상시키기도 함

# 2. 메모리 관리
## 가상 메모리
> 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법
- 메모리 자원을 추상화하여 사용자에게 매우 큰 메모리로 보이게 만든다.
- 따라서 작은 메모리를 가지고도 큰 가상 주소 공간을 제공한다.
- 가상 메모리 주소와 물리 메모리 주소가 매핑되어 있고 프로세스 주소 정보가 들어 있는 `페이지 테이블`로 관리된다. 이 때 속도 향상을 위해 TLB를 쓴다.
- TLB란? 페이지 테이블에 있는 리스트를 보관하여 CPU가 페이지 테이블까지 가지 않도록 해 속도를 향상시킬 수 있는 캐시 계층

- 장점  
  1. 사용자 프로그램이 메모리보다 커져도 된다. 즉 메모리 크기 제약이 없다.
  2. 각 사용자 프로그램이 더 작은 메모리를 차지하므로 더 많은 프로그램을 동시에 수행할 수 있다. 
     이에 따라 응답시간은 늘어나지 않으면서 CPU 이용률과 처리율이 높아진다.
  3. 프로그램을 메모리에 올리고 스왑(swap)하는데 필요한 입/출력 횟수가 줄어든다.
     따라서 프로그램들이 보다 빨리 실행된다.
  4. 가상메모리 파일의 공유를 쉽게 해주고 공유 메모리 구현을 가능하게 한다.
  5. 프로세스 생성을 효율적으로 처리할 수 있는 메커니즘도 제공한다.
- 단점  
  1. 구현이 어렵고, 잘못 사용 시 성능이 현저히 저하 될 수 있다.

### 요구 페이징(Demand Paging)
> 초기에 필요한 것들만 적재하고, 페이지들이 실행 과정에서 실제로 필요할 때 적재하는 기법  
- 즉, 한번도 접근되지 않는 페이지는 물리 메모리에 전혀 적재되지 않는다.  
<img width="506" alt="요구 페이징" src="https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/da14c5ee-ad05-4a1c-aaca-5310045965d1"> <br>

- 장점
  1. 실제 필요한 페이지들만 메모리로 읽어오므로 시간 낭비와 메모리 공간 낭비를 줄일 수 있다.
  2. 프로세스가 메모리에 존재하는 페이지들만 접근하는 한 실행은 정상적으로 진행된다.
     하지만 프로세스가 메모리에 올라와 있지 않는 페이지를 접근하려고 한다면?
     -> `페이지 부재 트랩(page-fault trap)` 발생

### 페이지 부재 트랩
<img width="506" alt="페이지부재트랩" src="https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/33af0ac4-4532-42d6-ae78-9c83be932780"> <br>
1. 자신이 사용하고자 하는 페이지가 페이지 테이블에 있는지 확인  
2. 만약 물리 메모리에 사용하려는 페이지가 없으면 Page fault exception을 발생시키고 커널 모드로 진입  
3. OS는 페이지 테이블 엔트리 정보 속에서 Backing storage 어느 위치에 페이지가 있는지 확인  
4. 확인한 페이지를 물리 메모리에 로드  
5. 페이지 테이블 업데이트  
6. 원래 작업 다시 재개  

### 스와핑(swapping)
> 메모리에 당장 사용하지 않는 영역을 하드디스크로 옮기고 하드디스크 일부분을 마치 메모리처럼 불러와 쓰는 것
- 마치 페이지 폴드가 일어나지 않는 것처럼 만든다

#### 페이지(page): 가상 메모리를 사용하는 최소 크기 단위
#### 프레임(frame): 실제 메모리를 사용하는 최소 크기 단위

## 스레싱(thrashing)
> 메모리의 페이지 폴트율이 높은 것을 의미하며, 컴퓨터의 심각한 성능 저하를 초래한다
- 메모리에 너무 많은 프로세스가 동시에 올라가 스와핑이 많이 일어날 때 발생
- CPU 이용률은 낮아져 운영체제는 CPU가 한가한 줄 알고 더 많은 프로세스를 메모리에 올림
- 이런 악순환이 반복한다.
- 해결법: 메모리 늘이기, HDD를 SSD로 바꾸기, 작업 세트, PFF

### 작업 세트
- 프로세스의 과거 사용 이력인 지역성을 통해 결정된 페이지 집합을 만들어서 미리 메모리에 로드하는 방법
- 탐색 비용과 스와핑이 줄어든다

### PFF(Page Fault Frequency)
- 상한선과 하한선 설정하는 방법
- 상한선에 도달하면 프레임을 늘리고 하한선에 도달하면 프레임을 줄인다

## 메모리 할당
- 메모리에 프로그램을 할당할 때는 `시작 메모리 위치`, `메모리의 할당 크기`를 기반으로 할당한다
- 연속 할당과 불연속 할당이 있다

## 1. 연속 할당
- 프로세스의 구성요소가 메모리에 `연속된` 주소로 저장되는 방식
- 고정 분할과 동적 분할이 있다

### 고정 분할
- 시스템 생성 시 주기억장치가 이미 특정 크기로 고정된 파티션들로 분할되는 방식
- 균등 분할과 비균등 분할이 있다
#### 균등 분할: 모든 파티션의 크기가 일정
**1. 프로세스 크기 > 파티션 고정 크기**  
프로세스를 모듈 단위로 나누어 디스크와 주기억장치 사이에서 할당을 제어하는 오버레이(Overlay) 기법이 사용되어야 한다. 그만큼 오버헤드가 증가한다.   
**2. 프로세스 크기 < 파티션 고정 크기**  
파티션을 프로세스가 효율적으로 사용못하고 공간이 남는 내부단편화 문제가 생긴다. 
#### 비균등 분할: 모든 파티션의 크기가 일정하지 x
#### 고정 분할 장점
- 원리가 단순하다.
- 시스템 생성 시 주기억장치가 미리 분할되므로 운영체제 오버헤드가 줄어든다.
#### 고정 분할 단점
- 파티션 수에 따라 프로세스 수가 제한받는다.
- 크기가 작은 프로세스는 효율적인 공간활용이 안 된다.
- 현재 고정분할을 사용하는 운영체제는 거의 없다.

### 동적 분할
- 프로세스가 주기억장치로 적재될 때 정확히 필요한 크기만큼 메모리를 할당한다. 파티션의 크기와 개수가 가변적이다.
- **외부단편화** 문제가 존재  
<img width="600" alt="외부단편화" src="https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/bf059a0b-f926-473a-9cfc-377998fda4a8"><br>
- 필요한 크기의 메모리를 할당하기에 내부단편화는 발생하지 않지만 프로세스가 재배치(Relocation)되는 과정에서 메모리가 사용되지 못하고 남는 부분이 생긴다.
- 외부단편화는 **메모리 집약**으로 해결할 수 있다. 그러나 시간이 오래 걸린다.
<img width="600" alt="메모리 집약" src="https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/0d97b9d0-6006-414b-82f4-495403717467"><br>
- 인접한 외부 단편화 두 공간을 합치는 통합 방법으로도 해결할 수 있다.

#### 배치 알고리즘
- 동적 분할은 메모리 집약이 최소로 일어나는 자유 블록을 선택하여 프로세스를 배치해야한다.  
1. 최적적합(best-fit) :  요청된 크기와 가장 근접한 크기의 메모리를 선택한다.   
2. 최초적합(first-fit) : 가장 최근에 배치되었던 메모리의 위치부터 크기가 충분한 메모리를 선택한다.   
3. 최악적합(worst-fit) : 사용가능한 메모리 중 가장 큰 것을 선택한다.   
최적적합이 가장 좋은 결과를 낼거 같지만 그렇지 않다. 작은 블록이 메모리 여기저기 생겨 외부단편화가 곳곳에 생긴다. 그 결과, 메모리 집약이 많이 일어나므로 좋지 못하다. 의외로 최악적합은 메모리 공간이 널널해서 다른 프로세스를 할당할 공간을 제공할 수 있다.

## 2. 불연속 할당
- 메모리를 동일한 크기의 페이지(보통 4KB)로 나누고 프로그램마다 페이지 테이블을 두어 이를 통해 메모리에 프로그램을 할당한다.
- 현대 운영체제가 쓰는 방법
- `페이징 기법`, `세그멘테이션`, `페이지드 세그멘테이션`이 불연속 할당이다.

### 페이징(paging)
- 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당
- 홀의 크기가 균일하지 않은 문제가 없어지지만 주소 변환이 복잡해진다

### 세그멘테이션(segmentation)
- 페이지 단위가 아닌 의미 단위인 세그먼트(segment)로 나누는 방식
- 코드와 데이터로 나누거나 코드 내의 작은 함수를 세그먼트로 놓고 나눌 수도 있다
- 공유와 보안에는 좋지만 홀 크기가 균일하지 않다

### 페이지드 세그멘테이션(paged segmentation)
- 프로그램을 의미 단위인 세그먼트로 나누는 방식
- 공유, 보안에도 좋고 페이지 단위도 균일하다

## 페이지 교체 알고리즘
- 메모리는 한정되어 있기 때문에 스와핑이 많이 일어난다
- 우리는 스와핑이 많이 일어나지 않도록 설계해야 한다
- 스와핑은 페이지 교체 알고리즘 기반으로 일어난다

### 1. 오프라인 알고리즘
- 먼 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 알고리즘
- 가장 좋은 방법이지만 우리가 미래를 어떻게 알아?
- 즉, 사용할 수는 없지만 다른 알고리즘의 상한기준이 된다

### 2. FIFO
![fifo](https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/c4cae0b0-2ec8-46f5-b43f-94ce41fe7da7)
- 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법

### 3. LRU
![lru](https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/307c60a2-fe33-4425-8d31-96fb92f9f3d0)
- Least Recentle Used
- 참조가 가장 오래된 페이지를 바꾸는 방법
- '오래된' 것을 파악하기 위해 각 페이지마다 계수기, 스택을 두어야 하는 문제점이 있다
- 보통 한정된 메모리를 나타내는 `이중 연결 리스트`와 이중 연결리스트에서 빠르게 찾을 수 있게 도와주는 `해시 테이블`을 사용한다.

### 4. NUR
<img width="506" alt="NUR" src="https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/27cfe779-afa9-45f0-a035-8c0a615ea60d"><br>
- Not Used Recently
- LRU에서 발전
- cloek 알고리즘이라고도 함
- 1은 최근에 참고함, 0은 참고하지 않음을 의미
- 시계 방향으로 돌면서 0을 찾고 0을 찾은 순간 해당 프로세스를 교체하고, 해당 부분을 1로 바꾼다

### 5. LFU
![lfu](https://github.com/SSAFYSEOUL06CSSTUDY/06CSSTUDY/assets/50236187/6c2e299b-e630-47f7-bd72-93390ac87454)
- Least Frequently Used
- 가장 참조 횟수가 적은 페이지를 교체
